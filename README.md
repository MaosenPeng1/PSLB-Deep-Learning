# Prpensity Score Local Balance (PSLB) Estimation Using Deep Learning
## Description
This project guides users how to implemented the PSLB deep learning method (LBC-Net) to estimate propensity scores introduced in 'A Deep Learning Approach to Nonparametric Propensity Score Estimation with Optimized Covariate Balance'. It consists of total 6 simulation settings and a real data analysis. All related files for each setting are contained in the zip file listed below,
- Kang and Schafer (2007) 
  - 5k (5000 sample size) [*]
    - True (correctly specified propensity score model)
    - Mis (mis-specified propensity score model)
    - Sensitivity Analysis (Network Layers)
  - 1k (1000 sample size)
    - True (correctly specified propensity score model)
    - Mis (mis-specified propensity score model)
- SSMR 
  - True (correctly specified propensity score model)
  - Mis (mis-specified propensity score model)
- EQLS (real data) 
  - Data Application [*]
  - Bootstrap (standard deviation)

*: The results of the file are shown in the main context of the article. 

Each file consists of two parts, estimation and evaluation. The estimation related to the deep learning are conducted using Python (.py) and others are implemented with R (.R). Besides the PSLB method, the file also includes logistic regression, CBPS, and deep learning method with BCE loss for estimation comparison. The figures and tables in the article are contained in the evaluation files. A seed file is in each simulation files so that the results can be reproductive. The details will illustrated below, along with a step by step guide using Kang and Schafer (2007) of 5000 sample size as an example.

## Installation and Setup
### Codes and Resources Used
* R: version -- 4.3.1
Editor: RStudio
Packages Required:
CBPS, dplyr, tidyr, ggplot2, knitr, kableExtra.

* Python: version -- 3.11.3
Editor: Visual Studio Code
Packages Required:
torch, numpy, pandas, sys, argparse.

* Sever: High Performance Computing (HPC) - Seadragon Cluster (Linux system)
Editor: X-Win32
Hardware Resources: Central Processing Unit (CPU)
Purpose: run deep learning code parallel on sever. The bash file (.lsf) is generated by the file called 'lsf_generation*.py'.

## Data
The simulated data is generated using the "*Simulation.R" file for all seeds in 'sim_seed.csv'. 

The real data here is the European Quality of Life Survey (EQLS) study data, which is available from the UK Data Service https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=7724\#!/access-data. The 'Get_Data_EQLS.R' presents the data cleaning details and descriptive analysis of the data. 
Here we also uploaded the cleaned data in file 'eqls_data.csv' as long as the file illustrating how we clean the data 'Get_Data_EQLS.R'. The EQLS is a survey conducted through questionnaires that encompasses adults from 35 European countries. We merged the data from the 2007 and 2011 iterations of the EQLS. Our focus is on determining whether conflicts between work and life balance, as self-reported by respondents, influence the mental well-being of the working adult population. The 2007 EQLS included 35,635 individuals, while the 2011 version had 43,636 participants. For ease of analysis, we omitted 21,800 participants from the 2007 dataset and 27,234 from the 2011 dataset due to incomplete information. Our final sample is comprised of 17,439 individuals experiencing conflicts in balancing work and life (either at work, at home, or both, referred to as cases) and 12,797 individuals with no or minor conflicts (referred to as controls). We assessed mental well-being as the outcome using the World Health Organization Five (WHO-5) well-being index, which ranges from 0 to 100. This index evaluates the respondent's emotional state over the preceding two weeks. The number of covariates is 70.

## Instructions
1. generate data using "*Simulation.R", you will get data and ck_h csv files. The ck_h contains the local points and adaptive bandwidth by default, one can specify or define there own local intervals. Note all R functions are included in the "Method.R" file.
2. implement different methods to the data to estimate the propensity scores. Logistic regression and CBPS methods can be applied by "Logistic and CBPS Model.R", which will output a R object saved to the local computer for further use. The BCE loss and PSLB-DL method are run on the sever using the "\*.py" files through the bash file generated from "lsf_generation*.py".
3. evaluate the global balance, local balance, and outcome estimation (mean outcome or average treatment effect) with "Figures and Tables.R". This code can output figures and tables presented in the article. 

## Step-by-step Example (Kang and Schafer (2007).zip -> 5k (5000 sample size))
To facilitate the review process and ensure the reproducibility of our results, please follow the detailed instructions below, organized into distinct steps for clarity and ease of execution. These steps are designed to guide you through the simulation, analysis, and evaluation phases of our study using the provided scripts and data files.

1. Data Simulation
- Script: `Kang_Schafer_Simulation.R`
- Seed File: `sim_seed.csv`
- Output: 100 simulated datasets and corresponding `ck_h.csv` files.

Simulate data with R script 'Kang_Schafer_Simulation.R' along with the seed file 'sim_seed.csv', which will output 100 simulated data and ck_h csv files. Inside the simulation file, users can specify the span $\rho$ to determine the locality and compute the adaptive bandwidth, here we use the default $\rho=0.1$. This process can be done on HPC cluster with command 'Rscript Kang_Schafer_Simulation.R' after loading the R module - 'module load R'. 
2. Generate bash files (.lsf) using 'parallel_logistic_cbps_lsf_generation.py': logistic and CBPS method (this will require 40 cores to perform parallel processes); 'BCE_lsf_generation.py': BCE method (require at least 2GB memory, 100 CPUs with 1 cores and extensive 2 hour wall-time); 'PSLB_lsf_generation.py': LBC-Net method (require require at least 2GB memory, 100 CPUs with 1 core and extensive 2 hour wall-time); 'Learning_rate_lsf_generation.py': grid search for learning rate for BCE and LBC-Net method consecutively. Then follow the instructions inside each file to run the program either in python or R on cluster. This will result in multiple csv results files, download all into the local computer. (Here we will need to evaluate the tunning parameter (learning rate) first so that we put the optimal learning rate (plot a simple scatter plot of loss $Q(\theta)$ in R to see the convergence behavior.) into the scripts for each method).  

In script 'PSLB_lsf_generation.py' of our LBC-Net method, we specify the device argument so that user may use the GPU node if accessible, but here we use CPUs as it is enough for such jobs. Then we load the data and bandwidths with specific seed. Next, we input all the initial parameters including batch size, input, hidden, and output dimensions, learning rate, total epochs. The hidden dimension was chosen from experience between the number of covariates and the total sample size. We created a dataloader that contains process of normalizing the data and creating intercept term. A VAE model is implemented that output the initial weights for our propensity score model. We train the model with VAE weights and output the fitted the propensity score. Our model is a three layer fully connected network with batch normalization and residual connections. Such model find optimal propensity scores that minimize our objective functions. The customized loss functions are 'local_balance_ipw_loss' and 'penalty_loss' (calibration loss in the article). 

3. Evaluate the results using local R with 'Figures and Tables.R'. This file will implemented the functions in 'Methods.R' to reproduce all the figures and tables presented in the article.

In addition, we conducted the sensitivity analysis using different network structures (different layers 3 to 6), similar steps are as above. This is inside the file 'Sensitivity Analysis (Network Layers)'.

## LICENSE
This project is licensed under the MIT License - see the LICENSE.txt file for details.

## Reference
Kang, J. D. and Schafer, J. L. Demystifying double robustness: A comparison of alternative strategies for estimating a population mean from incomplete data. Statistical Science, 22(4):523â€“539, 2007








  
